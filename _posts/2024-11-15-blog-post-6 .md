---
title: "MIT6.S081 Lab3 Pgtbl"  # 如:"MIT6.S081 Lab1 学习笔记"
date: 2025-05-21      # 必须和文件名一致！
categories:           # 分类（可选）
  - 学习笔记
  - 操作系统
tags:                 # 标签（可选）
  - MIT6.S081
  - Xv6
  - RISC-V
excerpt: "提高用户空间和内核空间之间传递数据的效率"  # 可选
toc: true            # 是否显示目录（可选）
toc_sticky: true     # 目录是否固定（可选）
---

## 1. Print a page table(easy)
实验要求打印第一个进程的页表内容，首先来实现最底层的打印函数：
```c
// kernel/vm.c
// 可以参考 kernel/vm.c 中的 freewalk 函数的递归方式
void
pgtblprint(pagetable_t pagetable, int level) {
    for (int i = 0; i < 512; i++) {
        pte_t pte = pagetable[i];
        // 检查是否有效
        if (pte & PTE_V) {
            printf("..");
            for (int j = level; j < 2; ++j) {
                printf(" ..");
            }
            // 进行打印
            printf("%d: pte %p pa %p\n", i, pte, PTE2PA(pte));
            // 对非叶子级页表项递归，继续打印子节点
            if ((pte & (PTE_R | PTE_W | PTE_X)) == 0) {
                uint64 child = PTE2PA(pte);
                pgtblprint((pagetable_t)child, level - 1);
            }
        }
    }
    return 0;
}
```

紧接着使用一个函数对打印函数进行封装调用：
```c
int
kpgtblprint(pagetable_t pagetable) {
    printf("page table %p\n", pagetable);
    return pgtblprint(pagetable, 2);
}
```

在 kernel/exec.c 中的 exec 函数的最后调用该函数进行打印

```c
int
exec(char *path, char **argv)
{
  ... ... 

  p->trapframe->sp = sp; // initial stack pointer
  proc_freepagetable(oldpagetable, oldsz);

  // 在这里调用 kpgtblprint 函数对第一个进程进行页表的打印
  if (p->pid == 1) {
    kpgtblprint(p->pagetable);
  }

  return argc; // this ends up in a0, the first argument to main(argc, argv)

 bad:
  if(pagetable)
    proc_freepagetable(pagetable, sz);
  if(ip){
    iunlockput(ip);
    end_op();
  }
  return -1;
}
```

可以在命令行输入 
```bash
./grade-lab-pgtbl pte
```
测试是否成功打印出页表

## 2. A kernel page table per process(hard)
这个实验比较有难度，要求给每一个用户进程都创建一个内核态页表，我们可以先在 kernel/proc.h 中为进程结构体添加一个新的内核页表
```c
// Per-process state
struct proc {
  
  ... ...
  
  struct file *ofile[NOFILE];  // Open files
  struct inode *cwd;           // Current directory
  char name[16];               // Process name (debugging)

  // 增加一条属性，存储每个进程的内核态页表
  pagetable_t kpgtbl;
};
```

还记得我们在 vm.c 源码中遇到的 kvminit 函数吗，它通过调用 kvmmap 函数对内核页表进行了初始化，我们如果想为用户创建内核页表的话也需要仿照着完成这一步，首先修改 kvmmap 使它可以为传入的页表而非仅仅 kernel_pagetable 服务
```c
void
kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm) {
    if (mappages(kpgtbl, va, sz, pa, perm) != 0) {
        panic("kvmmap");
    }
}
```

随后需要仿照 kvminit，写一个新的初始化函数

```c
// kernel/vm.c
void
new_kvminit() {

  pagetable_t kpgtbl = (pagetable_t)kalloc();

  memset(kpgtbl, 0, PGSIZE);

  // uart registers
  kvmmap(UART0, UART0, PGSIZE, PTE_R | PTE_W);

  // virtio mmio disk interface
  kvmmap(VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);

  // CLINT 只用于内核启动时，因此这里可以不进行映射
  /* // CLINT
  kvmmap(CLINT, CLINT, 0x10000, PTE_R | PTE_W); */

  // PLIC
  kvmmap(PLIC, PLIC, 0x400000, PTE_R | PTE_W);

  // map kernel text executable and read-only.
  kvmmap(KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

  // map kernel data and the physical RAM we'll make use of.
  kvmmap((uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);

  // map the trampoline for trap entry/exit to
  // the highest virtual address in the kernel.
  kvmmap(TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
}
```

用于翻译虚拟地址的 kvmpa 函数也要修改：
```c
uint64
kvmpa(pagetable_t kpgtbl, uint64 va)
{
  uint64 off = va % PGSIZE;
  pte_t *pte;
  uint64 pa;
  
  pte = walk(kpgtbl, va, 0);
  if(pte == 0)
    panic("kvmpa");
  if((*pte & PTE_V) == 0)
    panic("kvmpa");
  pa = PTE2PA(*pte);
  return pa+off;
}
```

在 kernel/proc.c 中，为每一个进程分配了共享空间的内核栈，要先把这一部分给去掉
```c
// kernel/proc.c
// initialize the proc table at boot time.
void
procinit(void)
{
  struct proc *p;
  
  initlock(&pid_lock, "nextpid");
  for(p = proc; p < &proc[NPROC]; p++) {
      initlock(&p->lock, "proc");

      // Allocate a page for the process's kernel stack.
      // Map it high in memory, followed by an invalid
      // guard page.
      // 将以下的代码注释掉
      /* char *pa = kalloc();
      if(pa == 0)
        panic("kalloc");
      uint64 va = KSTACK((int) (p - proc));
      kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
      p->kstack = va; */
  }
  kvminithart();
}
```

在 allocproc 函数，为进程创建私有内核页表
```c
static struct proc*
allocproc(void) {
  
   ...

   // An empty user page table.
   p->pagetable = proc_pagetable(p);
   if(p->pagetable == 0){
        freeproc(p);
        release(&p->lock);
        return 0;
    }

    // 创建内核页表，并且初始化
    pagetable_t 
    p->kpgtbl = new_kvminit();
    // 分配内核栈
    char* pa = kalloc();
    if (pa == 0) {
        panic("kallo");
    }
    // 将内核栈映射到固定虚拟地址，KSTACK 是一个宏，用于计算给定索引的内核栈的虚拟地址
    uint64 va = KSTACK((int)0);
    kvmmap(p->kpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
    // 记录内核栈的虚拟地址
    p->kstack = va;
  

   // Set up new context to start executing at forkret,
   // which returns to user space.
   memset(&p->context, 0, sizeof(p->context));
   p->context.ra = (uint64)forkret;
   p->context.sp = p->kstack + PGSIZE;

   return p;
}
```

到现在基本的构建工作已经完成了，但是在进程陷入内核态中时还是会使用全局内核页表，因此要去修改 kernel/proc.c 的 scheduler 函数，把进程私有的内核页表加载到 SATP 寄存器
```c
void
scheduler(void)
{
  ... ...

        p->state = RUNNING;
        c->proc = p;

        // 进行切换
        w_satp(MAKE_SATP(p->kpgtbl));
        sfence_vma();

        // 执行进程
        swtch(&c->context, &p->context);

        // 切换回全局页表
        kvminithart();

        // Process is done running for now.
        // It should have changed its p->state before coming back.
        c->proc = 0;

  ... ...
}
```

接下来，需要在进程结束的时候释放进程私有页表了
```c
static void
freeproc(struct proc *p) {
  if(p->trapframe)
    kfree((void*)p->trapframe);
  p->trapframe = 0;
  if(p->pagetable)
    proc_freepagetable(p->pagetable, p->sz);
  p->pagetable = 0;
  p->sz = 0;
  p->pid = 0;
  p->parent = 0;
  p->name[0] = 0;
  p->chan = 0;
  p->killed = 0;
  p->xstate = 0;

  // 释放内核栈
  void* kstack_pa = (void*)kvmpa(p->kpgtbl, p->kstack);
  kfree(kstack_pa);
  p->kstack = 0;
  // 释放进程私有页表，但是不可以释放指向的物理内存，这是因为涉及到内核运行的代码和数据，直接释放会导致内核崩溃
  freekpgtbl(p->kpgtbl);
  p->kpgtbl = 0;

  p->state = UNUSED;
}
```

接下来去解决 freekpgtbl 函数
```c
// kernel/vm.c
void
freekpgtbl(pagetable_t pagetable) {
    for (int i = 0; i < 512; ++i) {
        pte_t pte = pagetable[i];
        uint64 child = PTE2PA(pte);
        if ((pte & PTE_V) && (pte & (PTE_R | PTE_W | PTE_X)) == 0) {
            freekpgtbl((pagetable_t)child);
            pagetable[i] = 0;
        }
    }
    // 释放当前页表自身的内存
    kfree((void*)pagetable);
}
```
最后注意下去到 kernel/virtio_disk.c 中，因为 virtio_disk_rw 函数调用了 kvmpa 函数
```c
// kernel/virtio_disk.c
// 增加 proc.h 头文件
#include "proc.h"

... ...

void_disk_rw(struct buf *b, int write) {

    ... ...
    
    disk.desc[idx[0]].addr = (uint64)kvmpa(myproc()->kpgtbl, (uint64)&buf0);

    ... ...

}
```
到这里就完成啦，在命令行输入
```bash
./grade-lab-pgtbl usertests
```
检查是否通过。

## 3. Simplify copyin/copyinstr
我们在 vm.c 中学习了这两个函数的实现，都是用于从用户态向内核态拷贝数据的。现在每一个用户进程都拥有了私有的内核页表，这使得内核态也可以对用户态传入的指针进行解引用，而不再需要调用 walkaddr 函数寻址了。接下来我们需要在每次操作用户页表的时候同时更新内核页表，使得两个页表代码段保持同步。

先实现一个同步更新页表的函数
```c
// kernel/vm.c
kvmcopymapping(pagetable_t src, pagetable_t dst, uint64 start, uint64 sz) {
  pte_t* pte;
  uint64 pa;
  uint flags;

  // 向上对齐，避免重复映射
  for (uint64 i = PGROUNDUP(start); i < start; i += PGSIZE) {
    if ((pte = walk(src, i, 0)) == 0) {
      panic("kvmcopymapping: pte not exist");
    }
    if ((*pte & PTE_V) == 0) {
      panic("kvmcopymapping: page not valid");
    }
    pa = PTE2PA(*pte);


    // 设置权限为用户不可访问
    flags = PTE_FLAGS(*pte) & ~PTE_U;
    if (mappages(dst, i, PGSIZE, pa, flags) != 0) {
      goto err;
    }
  }
  return 0;

err:
  uvmunmap(dst, PGROUNDUP(start), (i - PGROUNDUP(start)) / PGSIZE, 0);
  return -1;
}
```

紧接着实现一个缩减内存的函数
```c
// kernel/vm.c
uint64
kvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz) {
  if (newsz >= oldsz) {
    return oldsz;
  }
  if (PGROUNDUP(newsz) < PGROUND(oldsz)) {
    int npages = (PGROUND(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
    // 解除映射但不释放对应内存
    uvmunmap(pagetable, PGROUNDUP(newsz), npages, 0);
  }
  return newsz;
}
```

在内核页表中，0 - PLIC 部分可以用于同步，因此要在 kernel/exec.c 中检查，避免程序内存超出范围
```c
// kernel/exec.c
int
exec(char *path, char **argv) {

  ... ...

  if ((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz)) == 0) {
    goto bad;
  }
  if (sz1 >= PLIC) {
    goto bad;
  }

  ... ...

}
```

将所有涉及到用户态页表的修改的函数都进行更新
```c
// kernel/exec.c
int
exec(char *path, char **argv) {

	... ...

  // Save program name for debugging.
  for(last=s=path; *s; s++)
    if(*s == '/')
      last = s+1;
  safestrcpy(p->name, last, sizeof(p->name));

  // 清除内核页表中对程序内存的旧映射，然后重新建立映射
  uvmunmap(p->kpgtbl, 0, PGROUNDUP(oldsz) / PGSIZE, 0);
  kvmcopymapping(pagetable, p->kpgtbl, 0, sz);

  ... ...

}
```

```c
// kernel/proc.c
int
fork(void) {

  ... ...

  // Copy user memory from parent to child.
  // 同时将新进程用户页表映射拷贝一份到新进程内核页表中 
  if (uvmcopy(p->pagetable, np->pagetable, p->sz) < 0 || 
      kama_kvmcopymapping(np->pagetable, np->kpgtbl, 0, p->sz) < 0) {
    freeproc(np);
    release(&np->lock);
    return -1;
  }
  np->sz = p->sz;

  ... ...

}
```

```c
// kernel/proc.c
int
growproc(int n) {
  uint sz;
  struct proc *p = myproc();

  sz = p->sz;
  if (n > 0) {
      uint64 newsz;
      if ((newsz = uvmalloc(p->pagetable, sz, sz + n)) == 0)
          return -1;

      // 内核页表中的映射同步扩大
      if (kvmcopymapping(p->pagetable, p->kpgtbl, sz, n) != 0) {
          uvmdealloc(p->pagetable, newsz, sz);
          return -1;
      }
      sz = newsz;
  }
  else if (n < 0) {
      uvmdealloc(p->pagetable, sz, sz + n);
      // 内核页表中的映射同步缩小
      sz = kvmdealloc(p->kpgtbl, sz, sz + n);
  }
  p->sz = sz;
  return 0;
}
```

```c
// kernel/proc.c
void
userinit(void)
{
  ... ...
  
  // allocate one user page and copy init's instructions
  // and data into it.
  uvminit(p->pagetable, initcode, sizeof(initcode));
  p->sz = PGSIZE;
  // 同步程序内存映射到进程内核页表中
  kvmcopymapping(p->pagetable, p->kpgtbl, 0, p->sz);      

  ......
}
```

最后在 vm.c 中修改 copyin 和 copyinstr 就完成啦
```c
// kernel/vm.c
int
copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
{
  return copyin_new(pagetable, dst, srcva, len);
}

int
copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
{
  return copyin_new(pagetable, dst, srcva, max);
}
```

这里的两个新函数在 kernel/vmcopyin.c 中已经实现了
```c
// Copy from user to kernel.
// Copy len bytes to dst from virtual address srcva in a given page table.
// Return 0 on success, -1 on error.
int
copyin_new(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
{
  struct proc *p = myproc();

  if (srcva >= p->sz || srcva+len >= p->sz || srcva+len < srcva)
    return -1;
  memmove((void *) dst, (void *)srcva, len);
  stats.ncopyin++;   // XXX lock
  return 0;
}

// Copy a null-terminated string from user to kernel.
// Copy bytes to dst from virtual address srcva in a given page table,
// until a '\0', or max.
// Return 0 on success, -1 on error.
int
copyinstr_new(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
{
  struct proc *p = myproc();
  char *s = (char *) srcva;
  
  stats.ncopyinstr++;   // XXX lock
  for(int i = 0; i < max && srcva + i < p->sz; i++){
    dst[i] = s[i];
    if(s[i] == '\0')
      return 0;
  }
  return -1;
}
```
现在我们完成整个难度不小的 Lab3，一定要再结合实验指导书和源码理解一下，保证掌握这一部分知识。
